{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts associated with Otolaryngology network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2023 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "\n",
    "# ----------------\n",
    "# Module imports\n",
    "# ----------------\n",
    "\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "import yaml\n",
    "import sys\n",
    "#import csv\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import requests_cache\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "import re # regex\n",
    "import logging # See https://docs.python.org/3/howto/logging.html\n",
    "\n",
    "# Set up cache for HTTP requests\n",
    "requests_cache.install_cache('http_cache', backend='sqlite', expire_after=300, allowable_methods=['GET', 'POST'])\n",
    "\n",
    "# Set up log for warnings\n",
    "# This is a system file and hard to look at, so its data are harvested and put into a plain text log file later.\n",
    "logging.basicConfig(filename='warnings.log', filemode='w', format='%(message)s', level=logging.WARNING)\n",
    "\n",
    "INSTITUTION_NO_MATCH_CUTOFF = 80 # The low cutoff for the fuzzy match score for an institution to be considered a match\n",
    "INSTITUTION_REVIEW_CUTOFF = 90 # The low cutoff for the fuzzy match score for an institution to be considered a match that does not require review\n",
    "\n",
    "# ----------------\n",
    "# Functions\n",
    "# ----------------\n",
    "\n",
    "# ORCID supports Ringgold, GRID, and ROR identifiers.\n",
    "# https://www.ringgold.com/ Limited to 10 searches per day\n",
    "# https://www.grid.ac/institutes GRID discontinued public releases at the end of 2021\n",
    "# https://ror.org/ ROR is now the principal identifier for organizations\n",
    "\n",
    "# ROR documentation: https://ror.readme.io/\n",
    "# ROR API documentation: https://ror.readme.io/docs/rest-api\n",
    "# ROR API endpoint URL: https://api.ror.org/organizations\n",
    "\n",
    "def search_for_institution_id(institution: str, query_type: str) -> List[Dict]:\n",
    "    \"\"\"Search for the ROR ID for an institution using the ROR API.\n",
    "    \n",
    "    Args:\n",
    "        institution: The name of the institution to search for.\n",
    "        query_type: The type of query to perform. Must be one of 'query' or 'affiliation'.\n",
    "    \n",
    "    Returns:\n",
    "        A list of dictionaries for possible institution matches with the name, id, and score.\n",
    "    \"\"\"\n",
    "    # ROR API endpoint\n",
    "    ror_api_endpoint = 'https://api.ror.org/organizations'\n",
    "\n",
    "    # ROR API parameters\n",
    "    if query_type == 'query' or query_type == 'affiliation':\n",
    "        # Institution search (generic search string)\n",
    "        ror_api_params = {\n",
    "            query_type: institution\n",
    "        }\n",
    "    else:\n",
    "        print(f'Error: Unknown query type: {query_type}')\n",
    "        return ''\n",
    "\n",
    "    # Send the request to the ROR API\n",
    "    ror_api_response = requests.get(ror_api_endpoint, params=ror_api_params)\n",
    "\n",
    "    # Get the status code\n",
    "    status_code = ror_api_response.status_code\n",
    "    if status_code != 200:\n",
    "        print(f'Error: ROR API returned status code {status_code}')\n",
    "        return ''\n",
    "    else:\n",
    "        # Convert the response to JSON\n",
    "        ror_api_response_json = ror_api_response.json()\n",
    "\n",
    "        # Get the list of organizations\n",
    "        organizations = ror_api_response_json['items']\n",
    "\n",
    "        results = []\n",
    "        # Loop through the organizations and extract the name and ROR ID\n",
    "        for organization in organizations:\n",
    "            org_dict = {}\n",
    "            # Get the name\n",
    "            org_dict['name'] = organization['organization']['name']\n",
    "\n",
    "            # Get the ROR ID\n",
    "            org_dict['id'] = organization['organization']['id']\n",
    "\n",
    "            results.append(org_dict)\n",
    "        return results\n",
    "\n",
    "def fuzzy_match_institutions(institution_name: str, search_results: List[Dict]) -> Tuple:\n",
    "    \"\"\"Fuzzy match an institution name to a list of search results.\n",
    "\n",
    "    Args:\n",
    "        institution_name: The name of the institution to match.\n",
    "        search_results: A list of dictionaries with the name and id of the institution.\n",
    "\n",
    "    Returns:\n",
    "        A tuple with the top match dictionary and the score.\n",
    "    \"\"\"\n",
    "    top_w_ratio_match = {}\n",
    "    top_w_ratio_score = 0\n",
    "    top_token_set_ratio_match = {}\n",
    "    top_token_set_ratio_score = 0\n",
    "    flagged = False\n",
    "\n",
    "    for search_result in search_results:\n",
    "        # Get the name of the institution from the search result\n",
    "        search_result_name = search_result['name']\n",
    "\n",
    "        # Calculate the fuzzy match ratio\n",
    "        w_ratio = fuzz.WRatio(institution_name, search_result_name)\n",
    "        #print(w_ratio, institution_name, search_result_name)\n",
    "        token_set_ratio = fuzz.token_set_ratio(institution_name, search_result_name)\n",
    "        #print(token_set_ratio, institution_name, search_result_name)\n",
    "        #print()\n",
    "\n",
    "        # Check if this is the top w_ratio match\n",
    "        if w_ratio > top_w_ratio_score:\n",
    "            top_w_ratio_match = search_result\n",
    "            top_w_ratio_score = w_ratio\n",
    "\n",
    "        # Check if this is the top token_set_ratio match\n",
    "        if token_set_ratio > top_token_set_ratio_score:\n",
    "            top_token_set_ratio_match = search_result\n",
    "            top_token_set_ratio_score = token_set_ratio\n",
    "\n",
    "    # Check whether the top w_ratio match is also the top token_set_ratio match\n",
    "    if top_w_ratio_match != top_token_set_ratio_match:\n",
    "        # Warn that the top w_ratio match is not the top token_set_ratio match\n",
    "        print('Warning: Top w_ratio match is not the top token_set_ratio match for', institution_name)\n",
    "        logging.warning('Top w_ratio match is not the top token_set_ratio match for ' + institution_name)\n",
    "        print('Top w_ratio match:', top_w_ratio_score, top_w_ratio_match)\n",
    "        logging.warning('Top w_ratio match: ' + str(top_w_ratio_score) + ' ' + str(top_w_ratio_match))\n",
    "        print('Top token_set_ratio match:', top_token_set_ratio_score, top_token_set_ratio_match)\n",
    "        logging.warning('Top token_set_ratio match: ' + str(top_token_set_ratio_score) + ' ' + str(top_token_set_ratio_match))\n",
    "        logging.warning('')\n",
    "        flagged = True\n",
    "    # Return the top w_ration match and score\n",
    "    return top_w_ratio_match, top_w_ratio_score, flagged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "raw_data = pd.read_csv('oto_network_analysis.csv', dtype=str)\n",
    "\n",
    "# Pull the unique values from the INSTITUTION column\n",
    "institutions = list(raw_data['INSTITUTION'].unique())\n",
    "#print(institutions)\n",
    "\n",
    "# Remove null np.nan values\n",
    "for institution in institutions:\n",
    "    if institution is np.nan:\n",
    "        institutions.remove(institution)\n",
    "\n",
    "#print(institutions)\n",
    "\n",
    "# For testing, limit the number of institutions to 15\n",
    "#institutions = institutions[:15]\n",
    "\n",
    "# Create a data frame to store the results\n",
    "results_df = pd.DataFrame(columns=['match_score', 'flagged', 'name', 'ror_label', 'ror_id'])\n",
    "\n",
    "# Loop through the institutions and search for the ROR ID\n",
    "for institution in institutions:\n",
    "    print(institution.strip())\n",
    "    # Search for the institution\n",
    "    institution_search_results = search_for_institution_id(institution, 'affiliation')\n",
    "    #print(json.dumps(institution_search_results, indent=2))\n",
    "\n",
    "    if len(institution_search_results) == 0:\n",
    "        results_dict = {\n",
    "            'match_score': 0,\n",
    "            'name': institution.strip(),\n",
    "            'ror_label': '',\n",
    "            'ror_id': '',\n",
    "            'flagged': 'no match'\n",
    "        }\n",
    "    else:\n",
    "        # Fuzzy match the institution name to the search results\n",
    "        id_match, score, flagged_mismatch = fuzzy_match_institutions(institution, institution_search_results)\n",
    "        #print(id_match)\n",
    "\n",
    "        if score < INSTITUTION_NO_MATCH_CUTOFF: # Score too low to be a match\n",
    "            results_dict = {\n",
    "                'match_score': 0,\n",
    "                'name': institution.strip(),\n",
    "                'ror_label': '',\n",
    "                'ror_id': '',\n",
    "                'flagged': 'no match'\n",
    "            }\n",
    "        else: # Score high enough to be a match\n",
    "            # Create a dictionary with the results\n",
    "            results_dict = {\n",
    "                'match_score': score,\n",
    "                'name': institution.strip(),\n",
    "                'ror_label': id_match['name'],\n",
    "                'ror_id': id_match['id']\n",
    "            }\n",
    "            if flagged_mismatch: # w_ratio match disagrees with token_set_ratio match\n",
    "                results_dict['flagged'] = 'mismatch'\n",
    "            else:\n",
    "                if score < INSTITUTION_REVIEW_CUTOFF: # Score too low to be accepted without review\n",
    "                    results_dict['flagged'] = 'review'\n",
    "                else:\n",
    "                    results_dict['flagged'] = ''\n",
    "\n",
    "    # Add the results to the data frame\n",
    "    results_df = results_df.append(results_dict, ignore_index=True)\n",
    "    print()\n",
    "\n",
    "    # Save the results to a CSV file after each institution in case the script crashes\n",
    "    results_df.to_csv('ror_id_search_results.csv', index=False)\n",
    "\n",
    "# direct output to text log file instead of sys.stdout\n",
    "error_log_object = open('log_error.txt', 'at', encoding='utf-8')\n",
    "\n",
    "# Read the warnings log\n",
    "# For some reason, the log is considered considered a binary file. So when it is read in as text, \n",
    "# it contains many null characters. So they are removed from the string read from the file.\n",
    "with open('warnings.log', 'rt') as file_object:\n",
    "    warnings_text = file_object.read().replace('\\0', '')\n",
    "if warnings_text == '':\n",
    "    print('No errors occurred.', file=error_log_object)\n",
    "else:\n",
    "    print(warnings_text, file=error_log_object)\n",
    "print('', file=error_log_object)\n",
    "\n",
    "# Close the log file\n",
    "error_log_object.close()\n",
    "print('done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
