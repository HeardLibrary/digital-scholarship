{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_cirrus.py, containing a function for performing a Cirrus search of Wikidata (or other wikibase) using its API.\n",
    "version = '0.1.0'\n",
    "created = '2023-02-22'\n",
    "\n",
    "# (c) 2023 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "# For more information, see https://github.com/HeardLibrary/linked-data/tree/master/vanderbot\n",
    "\n",
    "# General information on Wikimedia Search: https://www.mediawiki.org/wiki/API:Search_and_discovery\n",
    "# Wikimedia Search Platform team page: https://www.mediawiki.org/wiki/Wikimedia_Search_Platform\n",
    "# Details on CirrusSearch are at https://www.mediawiki.org/wiki/Help:CirrusSearch\n",
    "# Wikidata specific details are at https://www.mediawiki.org/wiki/Help:Extension:WikibaseCirrusSearch\n",
    "\n",
    "# Refer to https://www.mediawiki.org/wiki/API:Search_and_discovery for search API documentation\n",
    "# \"search\" query action using CirrusSearch (Elastic-based search engine):\n",
    "# https://www.wikidata.org/wiki/Special:ApiSandbox#action=query&format=json&list=search&formatversion=2&srsearch=baskauf\n",
    "# Returns Q IDs and descriptions (\"snippets\")\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "\n",
    "# See https://meta.wikimedia.org/wiki/User-Agent_policy for details of Wikimedia User-Agent policy\n",
    "user_agent_header = 'VanderSearchBot/' + version + ' (https://github.com/HeardLibrary/linked-data/tree/master/vanderbot; mailto:steve.baskauf@vanderbilt.edu)'\n",
    "request_header_dictionary = {\n",
    "\t'Accept' : 'application/json',\n",
    "\t'User-Agent': user_agent_header\n",
    "}\n",
    "search_session = requests.Session()\n",
    "# Set default User-Agent header so you don't have to send it with every request\n",
    "search_session.headers.update(request_header_dictionary)\n",
    "\n",
    "\n",
    "def search_cirrus(search_string: str, http: requests.Session, api_endpoint='https://www.wikidata.org/w/api.php') -> List[dict]:\n",
    "\t\"\"\"Search for a string using CirrusSearch (Elastic-based search engine)\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tsearch_string : str\n",
    "\t\tString to use in elastic search, produces same results as the Wikidata search box\n",
    "\thttp : requests.Session\n",
    "\t\tRequests HTTP session to use for search calls\n",
    "\tapi_endpoint : str\n",
    "\t\tURL of the endpoint, defaults to Wikidata\n",
    "\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tList[dict] : List of search results with keys \"qid\", \"description\", and \"label\"\n",
    "\t\"\"\"\n",
    "\trequest_string = '''{\n",
    "\t\t\"action\": \"query\",\n",
    "\t\t\"format\": \"json\",\n",
    "\t\t\"list\": \"search\",\n",
    "\t\t\"formatversion\": \"2\",\n",
    "\t\t\"srsearch\": \"''' + search_string + '''\"\n",
    "\t}'''\n",
    "\n",
    "\tresponse = http.get(api_endpoint, params=json.loads(request_string))\n",
    "\tdata = response.json()\n",
    "\t#print(json.dumps(data, indent=2))\n",
    "\n",
    "\thits = data['query']['search']\n",
    "\n",
    "\t# Look up the label for each item\n",
    "\tfor index, hit in enumerate(hits):\n",
    "\t\t# \"title\" in the search results is the Q ID\t\t\n",
    "\t\trequest_string = '''{\n",
    "\t\t\t\"action\": \"wbgetentities\",\n",
    "\t\t\t\"format\": \"json\",\n",
    "\t\t\t\"ids\": \"''' + hit['title'] + '''\",\n",
    "\t\t\t\"props\": \"labels\"\n",
    "\t\t}'''\n",
    "\t\tresponse = http.get(api_endpoint, params=json.loads(request_string))\n",
    "\t\tdata = response.json()\n",
    "\t\t#print(json.dumps(data, indent=2))\n",
    "\n",
    "\t\t# Match the Q ID to the label and add the label to the hits list\n",
    "\t\ttry:\n",
    "\t\t\thits[index]['label'] = data['entities'][hit['title']]['labels']['en']['value']\n",
    "\t\texcept:\n",
    "\t\t\thits[index]['label'] = ''\n",
    "\n",
    "\t#print(json.dumps(hits, indent=2))\n",
    "\n",
    "\t# Clean up the hits list by removing useless keys and renaming others\n",
    "\tclean_hits = []\n",
    "\tfor hit in hits:\n",
    "\t\tdel hit['ns']\n",
    "\t\tdel hit['pageid']\n",
    "\t\tdel hit['size']\n",
    "\t\tdel hit['wordcount']\n",
    "\t\tdel hit['timestamp']\n",
    "\t\thit['qid'] = hit['title']\n",
    "\t\tdel hit['title']\n",
    "\t\thit['description'] = hit['snippet']\n",
    "\t\tdel hit['snippet']\n",
    "\t\tclean_hits.append(hit)\n",
    "\n",
    "\n",
    "\treturn clean_hits\n",
    "\t\n",
    "search_string = 'Black practical theology'\n",
    "hits = search_cirrus(search_string, search_session)\n",
    "print(json.dumps(hits, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f96c65e2c1d4fcba82e9525c1be2fd15c6a14102f9c31bd3457b5f48c526190"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
