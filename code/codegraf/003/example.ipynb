{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXE6pdDaV1CS"
   },
   "source": [
    "# Simple script to input, calculate, and output\n",
    "\n",
    "Note: in Jupyter notebooks, we can make comments in Markdown cells.  So making inline comments (lines that start with the hash character # and are ignored by Python) is less important.  \n",
    "\n",
    "Here we set up the data needed to run the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EezrIC1EV1CX"
   },
   "outputs": [],
   "source": [
    "# This is an inline comment that will be ignored by Python\n",
    "pi = 3.14159\n",
    "print(pi)\n",
    "diameter = float(input('Enter the diameter, then press the Enter/return key: '))  # when this line runs you need to enter a number\n",
    "print(diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mVU7vUmV1CY"
   },
   "source": [
    "The data need to be transformed into a usable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKCVg7zBV1CZ"
   },
   "outputs": [],
   "source": [
    "radius = diameter/2\n",
    "print(radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz1g6Y-MV1CZ"
   },
   "source": [
    "We have all of the information necessary to complete the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUJaOu9OV1CZ"
   },
   "outputs": [],
   "source": [
    "print('The area of the circle is ',pi*radius**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V99pBeLYSYH7"
   },
   "source": [
    "# Using an API to plot the current location of the International Space Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJ_YekYKV1Ca"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import webbrowser\n",
    "\n",
    "url = 'http://api.open-notify.org/iss-now.json'\n",
    "response = requests.get(url)\n",
    "print('JSON text: ', response.text)\n",
    "print()\n",
    "data = response.json()\n",
    "print('Python data structure: ', data)\n",
    "print()\n",
    "latitude = data['iss_position']['latitude']\n",
    "longitude = data['iss_position']['longitude']\n",
    "zoom = '4'\n",
    "googleMapUrl = 'http://www.google.com/maps/place/'+latitude+','+longitude+'/@'+latitude+','+longitude+','+zoom+'z'\n",
    "print(googleMapUrl)\n",
    "# The following line will open a tab on your browser with the map if you run it in a local Jupiter notebook (but not in Colab)\n",
    "success = webbrowser.open_new_tab(googleMapUrl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T359phTZSx2w"
   },
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "There are a number of ways to do NER. This script uses the powerful Natural Language Toolkit (nltk).\n",
    "\n",
    "The first step is to load several libraries and download data needed by the apply the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxGjwkgiSz7O"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import json\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0GU4Vs0TWgW"
   },
   "source": [
    "The next step is to run the example text through a pipeline that breaks the text into words, flags the words by part of speech, then tags chunks of words that are thought to be named entites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEBpjI9sTZWD"
   },
   "outputs": [],
   "source": [
    "text = '''The House committee investigating the Jan. 6 attack on the U.S. Capitol on Tuesday evening unanimously approved a criminal contempt report against Steve Bannon, an ally of former President Donald Trump's, for defying a subpoena from the panel.'''\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print('tokens:', tokens)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "print('tagged:', tagged_tokens)\n",
    "named_entity_chunks = nltk.ne_chunk(tagged_tokens)\n",
    "print('Named Entity chunks:', named_entity_chunks)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnHqjglzT0l6"
   },
   "source": [
    "In this last step, we extract data from the pipeline output for human-friendly display and collect it in a Python data structure for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3hJmlsrT4OI"
   },
   "outputs": [],
   "source": [
    "ne_list = []\n",
    "for chunk in named_entity_chunks:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        ne_dict = {'ne_label': chunk.label()}\n",
    "        # A chunk is some kind of iterable of tuples\n",
    "        # Each tuple contains (word, noun_descriptor)\n",
    "        ne_string = chunk[0][0] # 0th tuple, word\n",
    "        # Iterate through the rest of the tuples in the chunk\n",
    "        for additional_tuple in chunk[1:len(chunk)]:\n",
    "            ne_string += ' ' + additional_tuple[0]\n",
    "        ne_dict['ne_string'] = ne_string\n",
    "        ne_list.append(ne_dict)\n",
    "\n",
    "        print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
    "print()\n",
    "print('NE list:', json.dumps(ne_list, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnfJF2lvUL8X"
   },
   "source": [
    "# Face detection using pretrained machine learning model using OpenCV\n",
    "\n",
    "The cv2 module is an open source computer vision library.\n",
    "\n",
    "We will use this image for a test:\n",
    "\n",
    "![Vanderbilt police car](https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Beatles_ad_1965_just_the_beatles_crop.jpg/320px-Beatles_ad_1965_just_the_beatles_crop.jpg)\n",
    "\n",
    "EMI., Public domain, via Wikimedia Commons\n",
    "\n",
    "**NOTE: After running this code, it's best not to save the notebook without first clearing the image output (`Edit` menu, then select `Clear all outputs`). Without clearing the output, the image data gets saved with the notebook and the time to save may be long.**\n",
    "\n",
    "In the first section of code, we load a number of modules and define two functions that we will use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwkIfyXmUxx6"
   },
   "outputs": [],
   "source": [
    "# Import libraries and define functions\n",
    "\n",
    "import numpy as np\n",
    "import urllib.request as urllib\n",
    "import cv2 \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def detect_faces(cascade, test_image, scaleFactor = 1.1):\n",
    "    # create a copy of the image to prevent any changes to the original one.\n",
    "    image_copy = test_image.copy()\n",
    "    \n",
    "    #convert the test image to gray scale as opencv face detector expects gray images\n",
    "    gray_image = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Applying the haar classifier to detect faces\n",
    "    faces_rect = cascade.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=5)\n",
    "    \n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        cv2.rectangle(image_copy, (x, y), (x+w, y+h), (0, 255, 0), 15)\n",
    "\n",
    "    image_dimensions = test_image.shape # .shape gives height, width, and layers\n",
    "\n",
    "    # Create a Python data structure for the face rectangles discovered\n",
    "    faces_dict = {'image_width': str(image_dimensions[1]), 'image_height': str(image_dimensions[0])}\n",
    "    faces_list = []\n",
    "    for i in faces_rect:\n",
    "        faces_list.append({'x': str(i[0]), 'y': str(i[1]), 'width': str(i[2]), 'height': str(i[3])})\n",
    "    faces_dict['faces'] = faces_list\n",
    "        \n",
    "    return image_copy, faces_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrMLj7mRVNbQ"
   },
   "source": [
    "The training data is available on the web, but cv2 expects that the training data are in a local file. So we grab the data from GitHub, save the file in the current working directory on the cloud server, then load the file to create a classifier object.\n",
    "\n",
    "There are 4 pretrained models that we can try by uncommenting them in the first section of code (delete the `#` sign from the one you want to use and insert `#` in front of the one you are finished with).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BbBiySoVTON"
   },
   "outputs": [],
   "source": [
    "# Uncomment to try a different training model\n",
    "training_file = 'haarcascade_frontalface_default.xml'\n",
    "#training_file = 'haarcascade_frontalface_alt.xml'\n",
    "#training_file = 'haarcascade_frontalface_alt2.xml'\n",
    "#training_file = 'haarcascade_frontalface_alt_tree.xml'\n",
    "\n",
    "# Load traning model from GitHub\n",
    "training_data_url = 'https://github.com/parulnith/Face-Detection-in-Python-using-OpenCV/raw/master/data/haarcascades/' + training_file\n",
    "training_data = requests.get(training_data_url).text\n",
    "\n",
    "# Save file on cloud server\n",
    "with open(training_file, 'wt', encoding='utf-8') as file_object:\n",
    "    file_object.write(training_data)\n",
    "\n",
    "haar_cascade_face = cv2.CascadeClassifier(training_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfmM0WmiWFdu"
   },
   "source": [
    "The final section of code retrieves the image from Wikimedia Commons via a URL, then loads it as a cv2 image. (The commented out code can be used if you are running the notebook locally and want to load the file from a path in your filesystem.)\n",
    "\n",
    "The `detect_faces()` function runs the machine learning model on the picture. The last line displays the image with rectangles superimposed to show any faces that were detected. The raw pixel rectangle data are available in the `faces_dict`, which you can view by uncommenting the print statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GH8PpEsWMSL"
   },
   "outputs": [],
   "source": [
    "# URL of test image\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/9/9f/Beatles_ad_1965_just_the_beatles_crop.jpg'\n",
    "\n",
    "#get image by url and load into cv2\n",
    "resp = urllib.urlopen(image_url)\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "# alternate code to load image from a local file\n",
    "# image = cv2.imread(path)\n",
    "\n",
    "#call the function to detect faces\n",
    "faces, faces_dict = detect_faces(haar_cascade_face, image)\n",
    "\n",
    "# uncomment to see the faces rectangles metadata\n",
    "#print(json.dumps(faces_dict, indent = 2))\n",
    "\n",
    "#convert to RGB and display image\n",
    "plt.imshow(convertToRGB(faces))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
