{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and changing DataFrame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows\n",
    "\n",
    "The simplest way to slice rows of a DataFrame is to use the `.head()` or `.tail()` methods if the rows that you want are at the start or end of the DataFrame. The result is another DataFrame object, a view of the original DataFrame. Recall that changes made to views will affect the original object. To avoid this, use the `.copy()` method.\n",
    "\n",
    "To slice using labels, need to use the `.loc()` method. To slice columns, we need to specify both indices, with \"all rows\" (`:`) selected as the first index.\n",
    "\n",
    "Recall that slicing with labels is inclusive of last label selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/r/wv5_women_and_development.csv'\n",
    "development = pd.read_csv(url)\n",
    "# Use the country name as the row label index\n",
    "development = development.set_index('country')\n",
    "development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_end = development.tail(12).copy()\n",
    "table_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see that the last 12 rows are summary statistics added after the last country. If we want the DataFrame to include only the countries, we could use `.head()` with a negative argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_only = development.head(-12).copy()\n",
    "countries_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an earlier lesson, we saw that we could use `.loc()` and `.iloc()` to retrieve single rows by their indices, resulting in a Series. As we did in the lesson on Series, we can use a range of indices or a list of indices to retrieve a slice. But when we slice a DataFrame this way, the result is another DataFrame containing rows from the source DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice by a range of label indices\n",
    "e_countries = development.loc['Ecuador':'Ethiopia']\n",
    "e_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice by a range of integer indices. Remember that slicing by integer index omits the last number.\n",
    "integer_slice = development.iloc[1:4]\n",
    "integer_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice by a list of label indices\n",
    "non_states = development.loc[ ['American Samoa', 'Puerto Rico', 'Virgin Islands (U.S.)'] ]\n",
    "non_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beginning or end of the range can be omitted to include all rows from the top or to the bottom, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_income = development.loc['Low income': ]\n",
    "by_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing a rectangular selection\n",
    "\n",
    "We can slice any rectangular selection of the DataFrame using `.loc()` or `.iloc()` and specifying the ranges on both axes: first the 0th one (rows), then the 1th one (columns), separated by a comma. Omit a starting or ending value to include the range starting from the beginning or to the end, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/r/wv5_women_and_development.csv'\n",
    "development = pd.read_csv(url)\n",
    "# Use the country name as the row label index\n",
    "development = development.set_index('country')\n",
    "development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use range of labels on both axes\n",
    "income_expectations = development.loc['Low income':'High income', 'male_life_expectancy_at_birth_2017': 'percentage_of_women_ages_20-24_first married_by_age_18' ]\n",
    "income_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify integer ranges, with the last number one more than the end of the interval you want.\n",
    "work = development.iloc[218:225, 3:7]\n",
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a list of indices instead of a range for one dimension\n",
    "female_values_by_income = development.loc['Low income':'High income', ['female_life_expectancy_at_birth_2017', 'female_employment_percentage', 'women_in_parliaments_percentage_seats'] ]\n",
    "female_values_by_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all countries through Zimbabwe and all columns from women_in_parliaments_percentage_seats to the end\n",
    "last_values_by_country = development.loc[ :'Zimbabwe', 'women_in_parliaments_percentage_seats': ]\n",
    "last_values_by_country.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing columns\n",
    "\n",
    "There is no simple way to slice only by columns. Rather, slice a rectangular selection that includes all rows. You can indicate \"all rows\" by including the colon range indicator (`:`) without any starting or ending values. The columns can be specified using any of the variations above (ranges or lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy = development.loc[ :, 'male_life_expectancy_at_birth_2017': 'female_life_expectancy_at_birth_2017']\n",
    "life_expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting ranges of rows or columns\n",
    "\n",
    "After slicing by rows or columns, the labels of the slice can be used to specify which rows or columns should be deleted. The labels of rows can be retrieved using the `.index` attribute and the labels of the columns can be retrieved using the `.columns` attribute. Once the set of labels has been retrieved, they can be passed into the `.drop()` method to indicate what should be dropped, using the same syntax as for dropping a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df = schools_df.set_index('School ID')\n",
    "schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df.index)\n",
    "schools_df.loc[375:460].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a range of rows\n",
    "schools_df = schools_df.drop(schools_df.loc[375:460].index)\n",
    "schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df.columns)\n",
    "schools_df.loc[:, 'Grade PreK 3yrs':'Grade 12'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop columns instead of rows, use the `axis='columns'` (or `axis=1`) argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df = schools_df.drop(schools_df.loc[:, 'Grade PreK 3yrs':'Grade 12'].columns, axis='columns')\n",
    "schools_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows by boolean conditions\n",
    "\n",
    "Recall from the lesson on Series that we can select some subset of items by generating a sequence of booleans where the `True` values indicate those that should be included and the `False` values indicate those that should be excluded. The same holds for DataFrames, but with the selection possible in either of the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the tiny states DataFrame from the earlier lesson\n",
    "text_series = pd.Series({'OH': 'Ohio', 'TN': 'Tennessee', 'AZ': 'Arizona', 'PA': 'Pennsylvania', 'AK': 'Alaska'})\n",
    "capital_series = pd.Series({'OH': 'Columbus', 'TN': 'Nashville', 'AZ': 'Phoenix', 'PA': 'Harrisburg', 'AK': 'Juneau'})\n",
    "population_series = pd.Series({'OH': 11799448, 'TN': 6910840, 'AZ': 7151502, 'PA': 13002700, 'AK': 733391})\n",
    "states_dict = {'text': text_series, 'capital': capital_series, 'population': population_series}\n",
    "states_df = pd.DataFrame(states_dict)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_booleans = pd.Series({\n",
    "    'OH': False,\n",
    "    'TN': True,\n",
    "    'AZ': True,\n",
    "    'PA': False,\n",
    "    'AK': True\n",
    "})\n",
    "row_booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the rows using .loc() as before, but using booleans instead of explicit naming.\n",
    "selected_states = states_df.loc[row_booleans]\n",
    "selected_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously it is a waste of time to hand-write the boolean values. But it is very easy to generate an appropriate boolean screening series by evaluating a condition. \n",
    "\n",
    "Some boolean operators in pandas differ somewhat from those in base Python, where the keywords `and`, `or`, and `not` are used. They are:\n",
    "\n",
    "| pandas operator | boolean | evaluation |\n",
    "| --------------- | ------- | -------- |\n",
    "| & | and | `True` if all `True` |\n",
    "| \\| | or | `True` if any `True` |\n",
    "| ~ | not | opposite value |\n",
    "\n",
    "The `==`, `>`, `<=`, etc. operators are the same as in base Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a boolean Series for selecting rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_selector = states_df['text'] == 'Alaska'\n",
    "row_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selector to locate the states to be included in the slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_star_state = states_df.loc[row_selector]\n",
    "north_star_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically we would not bother doing this in separate steps, but just nest the condition inside the `.loc[]` expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_arizona = states_df.loc[ ~(states_df['capital']=='Phoenix') ]\n",
    "not_arizona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more practical example using the schools data: select all middle schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df = schools_df.set_index('School ID')\n",
    "middle_schools = schools_df.loc[ schools_df['School Level']=='Middle School' ]\n",
    "middle_schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.isnull()` or `.notnull()` methods to select rows that have or don't have `NaN` values respectively. For examle we could look for high schools by finding rows that don't have missing values in the `Grade 12` column. However, you should note that isn't the same as filtering for high schools, since `Special Education` schools also have 12th graders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_schools = schools_df.loc[ schools_df['Grade 12'].notnull() ]\n",
    "high_schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns by boolean conditions\n",
    "\n",
    "Because of the way we typically organize data in tables, it's probably less common to select columns by a condition, but it can be done in a manner analogous to how we selected rows. Here we select columns by explicitly constructing a series of booleans for the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the columns using .loc() using booleans\n",
    "column_booleans = pd.Series({'text': True, 'capital': False, 'population': True})\n",
    "selected_columns = states_df.loc[:, column_booleans]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we would be more likely to create the boolian selector series by a condition. In this example, we ask the question \"Which columns have a value of `Harrisburg` in the row labeled `PA`?\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_selector = states_df.loc['PA'] == 'Harrisburg'\n",
    "column_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use that selector to slice the column that matches (the `capital` column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df.loc[:, column_selector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing values as a vectorized operation\n",
    "\n",
    "In the same way that we can select rows to slice them based on boolean conditions, we can also select cells in a column to change their values. Reload the schools data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df = schools_df.set_index('School ID')\n",
    "ethnicity = schools_df.loc[:, 'American Indian or Alaska Native':]\n",
    "ethnicity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some columns, cells were empty because the group wasn't represented (i.e. there were zero students) and the cells were left empty in the original table. Those empty cells were read into the DataFrame by pandas as `NaN` values. They aren't realy missing values -- rather they should have a value of zero.\n",
    "\n",
    "We can use `.loc` to select a single cell by specifying its row and column label indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity.loc[375, 'Native Hawaiian or Other Pacific Islander']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows us that the cell has a mising value. We can assign a new value to that cell location explicity using the row and column label indices and `.iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity.loc[375, 'Native Hawaiian or Other Pacific Islander'] = 0\n",
    "ethnicity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what we really want to do is to change every row in that column that has a `NaN` value to a zero. We can do that by first specifying a selector Series for that column that indicates whether each row has missing data (`True`) or not (`False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islander_missing_data_rows = ethnicity['Native Hawaiian or Other Pacific Islander'].isnull()\n",
    "islander_missing_data_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we use that Series in the column position of the `.loc` attribute, all rows in that column with `True` values (i.e. with missing data) will have their value set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity.loc[islander_missing_data_rows, 'Native Hawaiian or Other Pacific Islander'] = 0\n",
    "ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through rows\n",
    "\n",
    "One of the main purposes of pandas is to make it possible to perform operations on entire columns using vectorized operations. However, there are some situations where it makes sense to iterate through each row in the DataFrame and deal with values one row at a time. These situations would include complex operations that require multiple lines of code to describe, or actions that must happen sequentially, such as retrieving data from a URL.\n",
    "\n",
    "Our example will use information about websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = {\n",
    "    'name': {'alphabet': 'Google', 'vu': 'Vanderbilt', 'fake': 'Obsolete Website'}, \n",
    "    'url': {'alphabet': 'https://www.google.com/', 'vu': 'https://www.vanderbilt.edu/', 'fake': 'https://example.org/fake_url'},\n",
    "    'status': {'alphabet': 'unknown', 'vu': 'unknown', 'fake': 'unknown'}\n",
    "           }\n",
    "websites_df = pd.DataFrame(websites)\n",
    "websites_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate an iterable object from the DataFrame we use the `.iterrows()` method. Iterating using a `for` loop generates a tuple consisting of the label index and the data from the row, in the form of a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for website_tuple in websites_df.iterrows():\n",
    "    print(website_tuple)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the index and Series separately, we can unpack the tuple as we iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_index, website_series in websites_df.iterrows():\n",
    "    print(label_index)\n",
    "    print()\n",
    "    print(website_series)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned in the lesson on pandas Series, to access a value from the row Series, we can use `.loc` attribute, or direct indexing, which is simpler but perhaps more ambiguous since it can also be used for integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label_index, website_series in websites_df.iterrows():\n",
    "    print(website_series.loc['url'])\n",
    "    print(website_series['url'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating will allow us to check the status of each website one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "for label_index, website_series in websites_df.iterrows():\n",
    "    response = requests.get(website_series['url'])\n",
    "    if response.status_code == 200:\n",
    "        print(website_series['name'], 'is up.')\n",
    "        websites_df.loc[label_index, 'status'] = 'OK'\n",
    "    elif response.status_code == 404:\n",
    "        print(website_series['name'], 'is down.')\n",
    "        websites_df.loc[label_index, 'status'] = 'not found'\n",
    "    else:\n",
    "        print(website_series['name'], 'has status code', response.status_code)\n",
    "        websites_df.loc[label_index, 'status'] = 'other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to displaying the status to the user, the script also recorded the status in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking up values (optional)\n",
    "\n",
    "We can use the strategies from this lesson to look up values in one table and add them to another. In this example, we have a table with data about artists and another table with data about artworks. The artwork table is linked to the artist table by a unique identifier for the artist (the Wikidata Q ID of the artist). \n",
    "\n",
    "First read in the tables. I'm chosing to treat the dates as strings, so I use the `dtype=str` argument when I load each CSV into a DataFrame. I also set the `qid` as the label index for the artist and the `accession_number` as the label index for the artwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/artists.csv'\n",
    "# We want the years to be strings, not numbers\n",
    "artists = pd.read_csv(url, dtype=str)\n",
    "artists = artists.set_index('qid')\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/artworks.csv'\n",
    "works = pd.read_csv(url, dtype=str)\n",
    "works = works.set_index('accession_number')\n",
    "works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find an artist's name in the artist DataFrame using the Q ID label index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_index = 'Q105090067'\n",
    "artists.loc[artist_index, 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hard-coding the artist index, we can generate a Series of the artists for all of the works by inserting the `creator` column of the `works` DataFrame (`works['creator']`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.loc[works['creator'], 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the length of this series is the same as the number of rows in the DataFrame, we can add it as a column. However, the label indices of the Series doesn't match the label indices of the DataFrame rows. So turn the Series into a Python list using the `list()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(artists.loc[works['creator'], 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assign those values to a new column in the `works` DataFrame called `artist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works['artist'] = list(artists.loc[works['creator'], 'name'])\n",
    "works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are more complicated if you want to look up the artists by values in a column that isn't the label index. For example, now that we have the artist names in the `works` DataFrame, if we pretend that we didn't have the author `qid` index available, we could use the names to look up artists by matching those names to values in the `name` column of the `artists` DataFrame and then get some information about the artist, such as their birth date. There are probably several ways to do this, but the following is a way to do it based on strategies we already know.\n",
    "\n",
    "First create a boolean Series for selecting the row in the `artists` table that matches the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = 'Tōteki Unkoku'\n",
    "artists['name']==artist_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this boolean Series to locate the birth year in rows where the designated artist name matches the `name` column. If the artist names in the table are unique (only one row per artist name), only a single row will match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.loc[artists['name']==artist_name, 'birth_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the actual birth year value, not a Series with one value. We can use the `.iloc` attribute of the series to get the value of the 0th item in the Series or just use `[0]` to directly specify the integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists.loc[artists['name']==artist_name, 'birth_year'].iloc[0])\n",
    "print(artists.loc[artists['name']==artist_name, 'birth_year'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate through each row in the DataFrame and substitute the `artist` name value for the row instead of the hard-coded `artist_name` that we used before. The `artist_birth` date that we looked up can then be added as a value in a new column of the `works` DataFrame called `artist_birth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for accession_number, work in works.iterrows():\n",
    "    artist_birth = artists.loc[artists['name']==work['artist'], 'birth_year'][0]\n",
    "    works.loc[accession_number, 'artist_birth'] = artist_birth\n",
    "works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
