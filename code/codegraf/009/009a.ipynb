{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas data frames\n",
    "\n",
    "## References\n",
    "\n",
    "[pandas website](https://pandas.pydata.org/)\n",
    "\n",
    "Includes link to pdf for *pandas: powerful Python data analysis toolkit*, free online alternative to *Python for Data Analysis* by Wes McKinney \n",
    "\n",
    "[pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This is the standard import statement for pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6JE8Q1LPYt_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "\n",
    "DataFrames are two-dimensional data structures composed of Series with shared indices.\n",
    "\n",
    "DataFrames can be created from a dictionary of Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_series = pd.Series({'OH': 'Ohio', 'TN': 'Tennessee', 'AZ': 'Arizona', 'PA': 'Pennsylvania', 'AK': 'Alaska'})\n",
    "capital_series = pd.Series({'OH': 'Columbus', 'TN': 'Nashville', 'AZ': 'Phoenix', 'PA': 'Harrisburg', 'AK': 'Juneau'})\n",
    "population_series = pd.Series({'OH': 11799448, 'TN': 6910840, 'AZ': 7151502, 'PA': 13002700, 'AK': 733391})\n",
    "print(text_series)\n",
    "print()\n",
    "print(capital_series)\n",
    "print()\n",
    "print(population_series)\n",
    "\n",
    "states_dict = {'text': text_series, 'capital': capital_series, 'population': population_series}\n",
    "states_df = pd.DataFrame(states_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When created in this way, the dictionary keys are used as the column headers (column label indices) and each series becomes a column. The label indices of the series are shared by all of the rows as the row label indices.\n",
    "\n",
    "When you print a pandas DataFrame, you get a text representation. If the name is given as the last line of the notebook cell, it's displayed in a \"prettier\" form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a column\n",
    "\n",
    "We can specify a column by using its column header as the label index in square brackets. The resulting column is a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df['capital'])\n",
    "print()\n",
    "print(type(states_df['capital']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot notation is an alternative if header string is a valid Python object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a row\n",
    "\n",
    "Select a row using `.loc` with the label index and `.iloc` with the integer position. The resulting output is a series, with the column labels as its label indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.loc['AZ'])\n",
    "print()\n",
    "print(states_df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a cell\n",
    "\n",
    "Select a cell using `.loc` with the label index and column label. The resulting output is the type of data containted in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.loc['PA', 'population'])\n",
    "print(type(states_df.loc['PA', 'population']))\n",
    "print(states_df.loc['AK', 'capital'])\n",
    "print(type(states_df.loc['AK', 'capital']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing column and row labels\n",
    "\n",
    "The `.columns` and `.index` attributes return the label indices for columns and rows as index objects. They can be converted into Python lists using the `list()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.columns)\n",
    "print()\n",
    "print(list(states_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(states_df.index)\n",
    "print()\n",
    "print(list(states_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The big picture\n",
    "\n",
    "From this exploration, we can see that a pandas DataFrame can be thought of as a table, with rows and columns that are pandas Series. When we extract either a row or column, it will have the same behavior as we saw for Series in the previous lesson.\n",
    "\n",
    "We can force a row or column into a simpler form, such as a list or dictionary by applying a conversion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(states_df['text'])\n",
    "print(states_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennsylvania_dictionary = dict(states_df.loc['PA'])\n",
    "print(pennsylvania_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a DataFrame from a file\n",
    "\n",
    "Although there are a number of ways to build a pandas DataFrame from simpler Python objects, most of the time we will create them from data that are already in tablular form in a file. \n",
    "\n",
    "The exact mechanism for loading the DataFrame will depend on the kind of environment you are running Python in (Colab notebook, Jupyter notebook, stand-alone Python) and the kind of file you are opening (CSV or Excel). We will start with the simplest example, loading a CSV from a URL, because it works the same in every environment.\n",
    "\n",
    "You can load a CSV file by passing in its URL as the argument of the `.read_csv()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9hbgvpcTvxH"
   },
   "outputs": [],
   "source": [
    "schools_df = pd.read_csv('https://raw.githubusercontent.com/HeardLibrary/digital-scholarship/master/data/gis/wg/Metro_Nashville_Schools.csv')\n",
    "schools_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for reading and writing from files\n",
    "\n",
    "`pd.read_csv()` read from a CSV file into a data frame.\n",
    "\n",
    "`pd.to_csv()` write from a data frame to a CSV file.\n",
    "\n",
    "`pd.read_excel()` read from an Excel file into a data frame.\n",
    "\n",
    "`pd.to_excel()` write from a data frame to an Excel file.\n",
    "\n",
    "For details about reading from particular sheets in an Excel file, delimiters other than commas, etc. see the [pandas User Guide](https://pandas.pydata.org/docs/user_guide/io.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the DataFrame\n",
    "\n",
    "If a DataFrame is large, it will be difficult to examine the whole thing at once. We can use several methods to view characteristics of the DataFrame.\n",
    "\n",
    "The `.head()` method will display the first 5 rows of the DataFrame. You can pass in a different number of rows to display as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlCEr3cZVOo0"
   },
   "outputs": [],
   "source": [
    "schools_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frames do not automatically have assigned index labels. We can use one of the series as the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other methods to explore a DataFrame:\n",
    "- `.tail()` to display the last lines of the DataFrame\n",
    "- `.shape` returns the number of rows and columns as a tuple.\n",
    "- `.columns` returns the column names as a pandas Index object. Use the `list()` function to convert into a simple Python list.\n",
    "- `.index` returns the row label indices as a pandas Index object. Use the `list()` function to convert into a simple Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types in a DataFrame from a CSV\n",
    "\n",
    "When a DataFrame is read in from a CSV, pandas tries to guess the type of data in the column. The result might be integer, floating point number, or \"object\", which is used for strings and mixed content types. To see this, look at the `dtype` value following each of the Series extracted from these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df['Male'])\n",
    "print()\n",
    "print(schools_df['Latitude'])\n",
    "print()\n",
    "print(schools_df['School Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you would like for all columns to be read in as strings -- for example when numbers are being used as identification strings and you don't want leading zeros to be dropped. To do this, use a `dtype=str` argument.\n",
    "\n",
    "Notice the change in data types in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url, dtype=str)\n",
    "\n",
    "print(schools_df['Male'])\n",
    "print()\n",
    "print(schools_df['Latitude'])\n",
    "print()\n",
    "print(schools_df['School Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty cells are typically read in as the NumPy missing data indicator: `NaN` (Not a Number). Notice the values for `Native Hawaiian or Other Pacific Islander` in rows where those cells were blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force blank cells to be read in as empty strings instead of as missing data using the `na_filter=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url, na_filter=False)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful because turning off the NaN filter will cause numeric columns to be a mixture of strings and numbers, changing the column type from one of the numeric types to \"object\". That may cause problems if you need to do calculations using that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df['Grade PreK 3yrs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, the `na_filter=False` argument is most likely to be used together with the `dtype=str` argument when you want all cells of the table to be strings (including empty strings for empty cells).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the row label indices\n",
    "\n",
    "When a DataFrame is read in from a CSV, pandas does not know what to use for the row label indices. So it defaults to using a sequence of integers (starting with 0) as the row labels. Notice these indices on the left in the table display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify one of the columns in the table to be converted into the row label indices using the `.set_index()` method, with the column header as the argument.\n",
    "\n",
    "If we set row label indices, typically we would like to use some kind of unique identifier for the row. In the case of the schools data, the `School ID` column will serve this purpose well. After running the following cell, notice that the `School ID`is no longer a regular column. It is now shown at the left in the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df = schools_df.set_index('School ID')\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use values from a column as the row index but want that column to remain as part of the data, you can create the index from the column rather than converting the column into the index. The following cell does that. Notice that `School ID` appears both on the left side (as the row label index) but also as the third data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.index = schools_df['School ID']\n",
    "schools_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy DataFrame operations\n",
    "\n",
    "Organizing data in a DataFrame makes it easy to do some operations that affect all rows at once. In the remaining sections we will try some of these operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-based calculations and adding a column\n",
    "\n",
    "Start by reloading the dataframe and setting the row label index to the State School ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df = schools_df.set_index('School ID')\n",
    "schools_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new column in the table from others, perform a vectorized operation on the source columns and refer to the new column by its label index. The schools data does not include a column for total number of students per school, so we can calculate it by adding the male and female columns and assigning the result to a new `total` column. The column will appear at the right end of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df['total'] = schools_df['Male'] + schools_df['Female']\n",
    "schools_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify a column, asign the result of a calculation involving the column back into the same named column. In this example, we convert the `Limited English Proficiency` column from number of students to percent of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df['Limited English Proficiency'] = schools_df['Limited English Proficiency'] / schools_df['total'] * 100\n",
    "schools_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "To sort a DataFrame by values in a particular column, we can use the `.sort_values()` method as we did with Series. However, since there are many possible columns to sort by, we use a `by` keyword argument. The value of the argument is a list of the columns to be used in the sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.sort_values(by=['Limited English Proficiency'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the code above only displays the result since the result wasn't assigned to anything. To save the result in the same DataFrame, either asign it to the same dataframe name, or use the `inplace=True` argument. To save a copy of the results under a new name, use the `.copy()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_schools_df = schools_df.sort_values(by=['Limited English Proficiency'], ascending=False).copy()\n",
    "sorted_schools_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum, mean, and standard deviation\n",
    "\n",
    "If a data frame consists of numbers, it is easy to calculate either the mean or sum of either rows or columns. \n",
    "\n",
    "The two dimensions of the DataFrame are called axes. The direction moving down through the rows is axis 0 and the axis moving across the columns is axis 1. \n",
    "\n",
    "To find the sum in a particular direction we can use `.sum()` and specify the axis using the keyword argument `axis`:\n",
    "\n",
    "```\n",
    "state_co2_sector.sum(axis=0)\n",
    "```\n",
    "\n",
    "Alternatively, we can use the axis labels `columns` or `rows` to indicate the direction we are summing across:\n",
    "\n",
    "```\n",
    "state_co2_sector.sum(axis='rows')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector = state_co2_sector.set_index('State')\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_co2_sector.sum(axis=0))\n",
    "print()\n",
    "print(state_co2_sector.sum(axis='rows'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that since calcuation of the sum is a vectorized operation, the answer is not a single vector, but rather it is a Series.\n",
    "\n",
    "The length of the resulting Series corresponds to a dimension of the DataFrame. So if we calculate the sum moving across the columns, we can add the sum Series to the DataFrame as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_co2_sector['total'] = state_co2_sector.sum(axis='columns')\n",
    "state_co2_sector.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_co2_sector.loc['total'] = state_co2_sector.sum(axis='rows')\n",
    "state_co2_sector.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for calculating the mean and standard deviation is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector = state_co2_sector.set_index('State')\n",
    "state_co2_sector.loc['mean'] = state_co2_sector.mean(axis='rows')\n",
    "state_co2_sector.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector = state_co2_sector.set_index('State')\n",
    "state_co2_sector.loc['std_dev'] = state_co2_sector.std(axis='rows')\n",
    "state_co2_sector.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing a column or row\n",
    "\n",
    "You can use the `.drop()` method to remove a single row or list of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a single row\n",
    "state_co2_sector = state_co2_sector.drop('std_dev')\n",
    "state_co2_sector.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a list of rows\n",
    "state_co2_sector = state_co2_sector.drop(['Alabama', 'Arizona', 'Arkansas', 'Alaska'])\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a column or list of columns, specify the `columns` axis (or axis 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a single column\n",
    "state_co2_sector = state_co2_sector.drop('Commercial', axis='columns')\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a list of columns\n",
    "state_co2_sector = state_co2_sector.drop(['Residential', 'Transportation', 'Industrial'], axis=1)\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposing rows and columns\n",
    "\n",
    "Use the `.transpose()` or short form `.T` to switch rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector = state_co2_sector.set_index('State')\n",
    "switched_co2_data = state_co2_sector.transpose()\n",
    "switched_co2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames\n",
    "\n",
    "If tables have identical columns, it's relatively easy to concatenate one DataFrame below the other using the `.concat()` function by passing in a list of the names of the DataFrames to be combined. The function returns the combined DataFrame, which can be assigned to a new name or can replace one of the original ones.\n",
    "\n",
    "In the following example, records from a new Wikidata upload session are added to previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/book_chapter_authors1.csv'\n",
    "authors1 = pd.read_csv(url)\n",
    "authors1 = authors1.set_index('qid')\n",
    "authors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/book_chapter_authors2.csv'\n",
    "authors2 = pd.read_csv(url)\n",
    "authors2 = authors2.set_index('qid')\n",
    "authors2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a completely new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors = pd.concat([authors1, authors2])\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the second DataFrame onto the first, replacing the earlier version of the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors1 = pd.concat([authors1, authors2])\n",
    "authors1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the row labels are preserved when the DataFrames are concatenated.\n",
    "\n",
    "If we don't have a unique identifier for each row we might opt to not asign any label index to the rows. In that case, the automatically assigned numeric label indices will carry through after the concatination, resulting in non-unique row indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/book_chapter_authors1.csv'\n",
    "authors1 = pd.read_csv(url)\n",
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/book_chapter_authors2.csv'\n",
    "authors2 = pd.read_csv(url)\n",
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/book_chapter_authors3.csv'\n",
    "authors3 = pd.read_csv(url)\n",
    "authors = pd.concat([authors1, authors2, authors3])\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid this by using an `ignore_index=True` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_unique = pd.concat([authors1, authors2, authors3], ignore_index=True)\n",
    "authors_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining DataFrames by a shared column\n",
    "\n",
    "Sometimes you want to perform a calculation using information from two different tables. It may be easiest to do this by joining the two tables first. First load data on state populations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/population_by_state_2020.csv'\n",
    "state_populations_2020 = pd.read_csv(url)\n",
    "state_populations_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then reload the CO<sub>2</sub> data without setting the state name as the row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can carry out either an outer join by matching the two tables using the state name columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_outer = pd.merge(state_populations_2020, state_co2_sector, left_on=['NAME'], right_on=['State'], how='outer')\n",
    "state_data_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did an outer join, Puerto Rico, which is in one DataFrame but not the other, is included in the result, with `NaN` missing data values inserted. If we want to include only rows where data are available in both tables, we can do an inner join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_inner = pd.merge(state_populations_2020, state_co2_sector, left_on=['NAME'], right_on=['State'], how='inner')\n",
    "state_data_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it together\n",
    "\n",
    "If we wanted to calculate the per capita energy use, we could do this series of operations:\n",
    "\n",
    "1. Calculate the total energy use for all states.\n",
    "2. Join the DataFrames.\n",
    "3. Multipy by a million to get total metric tons and divide by the population to get metric tons per person.\n",
    "\n",
    "(This is a bogus analysis since it uses 2020 population data and 2016 CO<sub>2</sub> data, but we'll do it anyway.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "state_co2_sector = state_co2_sector.set_index('State')\n",
    "state_co2_sector['total'] = state_co2_sector.sum(axis='columns')\n",
    "state_co2_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/population_by_state_2020.csv'\n",
    "state_populations_2020 = pd.read_csv(url)\n",
    "state_data_inner = pd.merge(state_populations_2020, state_co2_sector, left_on=['NAME'], right_on=['State'], how='inner')\n",
    "state_data_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_inner['per_capita'] = state_data_inner['total'] * 1000000 / state_data_inner['POP_2020']\n",
    "state_data_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might as well clean up by sorting by per capita use and setting the row label indices again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_inner = state_data_inner.set_index('NAME')\n",
    "state_data_inner.sort_values('per_capita', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results\n",
    "\n",
    "Since the source files were retreived through Internet URLs, we can't save the processed DataFrame directly online. However, we can save it to the current working directory as either a CSV or Excel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_inner.to_excel('state_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: if you are using Colab, the file will be saved in the cloud, not on your local computer. So you should mount your Google Drive and set the path so that the file will end up there. You then will be able to retrieve it. The path shown below is the default path to the root of your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_drive_root_path = '/content/drive/MyDrive/'\n",
    "state_data.to_csv(google_drive_root_path + 'state_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the row label indices are saved as the first column in the file. In this example, that's fine because we want the state names to be included. However, if the rows have only the default numeric row label indices, we probably don't want to export those. We can suppress that using an `index = False` argument. Run the following cells and examine the content of the resulting files to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '' # use this line to save in the current working directory\n",
    "#root_path = '/content/drive/MyDrive/' # uncomment this line if using Colab\n",
    "\n",
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/codegraf/co2_state_2016_sector_nototals.xlsx'\n",
    "state_co2_sector = pd.read_excel(url)\n",
    "\n",
    "state_co2_sector.to_csv(root_path + 'state_data_numeric_label_index.csv')\n",
    "state_co2_sector.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_co2_sector.to_csv(root_path + 'state_data_no_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice exercise\n",
    "\n",
    "Use the code below to get started loading your own spreadsheet. It assumes an Excel file that is in your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_file.xlsx'\n",
    "practice_dataframe = pd.read_excel(filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "file_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
