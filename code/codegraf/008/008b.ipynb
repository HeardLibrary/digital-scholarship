{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas data frames\n",
    "\n",
    "## References\n",
    "\n",
    "[pandas website](https://pandas.pydata.org/)\n",
    "\n",
    "Includes link to pdf for *pandas: powerful Python data analysis toolkit*, free online alternative to *Python for Data Analysis* by Wes McKinney \n",
    "\n",
    "[pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This is the standard import statement for pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6JE8Q1LPYt_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "\n",
    "DataFrames are two-dimensional data structures composed of Series with shared indices.\n",
    "\n",
    "DataFrames can be created from a dictionary of Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_series = pd.Series({'OH': 'Ohio', 'TN': 'Tennessee', 'AZ': 'Arizona', 'PA': 'Pennsylvania', 'AK': 'Alaska'})\n",
    "capital_series = pd.Series({'OH': 'Columbus', 'TN': 'Nashville', 'AZ': 'Phoenix', 'PA': 'Harrisburg', 'AK': 'Juneau'})\n",
    "population_series = pd.Series({'OH': 11799448, 'TN': 6910840, 'AZ': 7151502, 'PA': 13002700, 'AK': 733391})\n",
    "print(text_series)\n",
    "print()\n",
    "print(capital_series)\n",
    "print()\n",
    "print(population_series)\n",
    "\n",
    "states_dict = {'text': text_series, 'capital': capital_series, 'population': population_series}\n",
    "states_df = pd.DataFrame(states_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When created in this way, the dictionary keys are used as the column headers (column label indices) and each series becomes a column. The label indices of the series are shared by all of the rows as the row label indices.\n",
    "\n",
    "When you print a pandas DataFrame, you get a text representation. If the name is given as the last line of the notebook cell, it's displayed in a \"prettier\" form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a column\n",
    "\n",
    "We can specify a column by using its column header as the label index in square brackets. The resulting column is a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df['capital'])\n",
    "print()\n",
    "print(type(states_df['capital']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot notation is an alternative if header string is a valid Python object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a row\n",
    "\n",
    "Select a row using `.loc` with the label index and `.iloc` with the integer index. The resulting output is a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_df.loc['AZ'])\n",
    "print()\n",
    "print(states_df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The big picture\n",
    "\n",
    "From this exploration, we can see that a pandas DataFrame can be thought of as a table, with rows and columns that are pandas Series. When we extract either a row or column, it will have the same behavior as we saw for Series in the previous lesson.\n",
    "\n",
    "We can force a row or column into a simpler form, such as a list or dictionary by applying a conversion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(states_df['text'])\n",
    "print(states_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennsylvania_dictionary = dict(states_df.loc['PA'])\n",
    "print(pennsylvania_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_info.iat[2, 1]\n",
    "organism_info.at['spider', 'group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a DataFrame from a file\n",
    "\n",
    "Although there are a number of ways to build a pandas DataFrame from simpler Python objects, most of the time we will create them from data that are already in tablular form in a file. \n",
    "\n",
    "The exact mechanism for loading the DataFrame will depend on the kind of environment you are running Python in (Colab notebook, Jupyter notebook, stand-alone Python) and the kind of file you are opening (CSV or Excel). We will start with the simplest example, loading a CSV from a URL, because it works the same in every environment.\n",
    "\n",
    "You can load a CSV file by passing in its URL as the argument of the `.read_csv()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9hbgvpcTvxH"
   },
   "outputs": [],
   "source": [
    "schools_df = pd.read_csv('https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv')\n",
    "schools_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the DataFrame\n",
    "\n",
    "If a DataFrame is large, it will be difficult to examine the whole thing at once. We can use several methods to view characteristics of the DataFrame.\n",
    "\n",
    "The `.head()` method will display the first 5 rows of the DataFrame. You can pass in a different number of rows to display as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlCEr3cZVOo0"
   },
   "outputs": [],
   "source": [
    "schools_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frames do not automatically have assigned index labels. We can use one of the series as the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other methods to explore a DataFrame:\n",
    "- `.tail()` to display the last lines of the DataFrame\n",
    "- `.shape` returns the rows and columns as a tuple.\n",
    "- `.columns` returns the column names as a pandas Index object. Use the `list()` function to convert into a simple Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df.columns)\n",
    "print()\n",
    "print(list(schools_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types in a DataFrame from a CSV\n",
    "\n",
    "When a DataFrame is read in from a CSV, pandas tries to guess the type of data in the column. The result might be integer, floating point number, or \"object\", which is used for strings and mixed content types. To see this, look at the `dtype` value following each of the Series extracted from these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df['Male'])\n",
    "print()\n",
    "print(schools_df['Latitude'])\n",
    "print()\n",
    "print(schools_df['School Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you would like for all columns to be read in as strings -- for example when numbers are being used as identification strings and you don't want leading zeros to be dropped. To do this, use a `dtype=str` argument.\n",
    "\n",
    "Notice the change in data types in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url, dtype=str)\n",
    "\n",
    "print(schools_df['Male'])\n",
    "print()\n",
    "print(schools_df['Latitude'])\n",
    "print()\n",
    "print(schools_df['School Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty cells are typically read in as the NumPy missing data indicator: `NaN` (Not a Number). Notice the values for `Native Hawaiian or Other Pacific Islander` in rows where those cells were blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force blank cells to be read in as empty strings instead of as missing data using the `na_filter=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url, na_filter=False)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful because turning off the NaN filter will cause numeric columns to be a mixture of strings and numbers, changing the column type from one of the numeric types to \"object\". That may cause problems if you need to do calculations using that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schools_df['Grade PreK 3yrs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, the `na_filter=False` argument is most likely to be used together with the `dtype=str` argument when you want all cells of the table to be strings (including empty strings for empty cells).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the row label indices\n",
    "\n",
    "When a DataFrame is read in from a CSV, pandas does not know what to use for the row label indices. So it defaults to using a sequence of integers (starting with 0) as the row labels. Notice these indices on the left in the table display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify one of the columns in the table to be converted into the row label indices using the `.set_index()` method, with the column header as the argument.\n",
    "\n",
    "If we set row label indices, typically we would like to use some kind of unique identifier for the row. In the case of the schools data, the `School ID` column will serve this purpose well. After running the following cell, notice that the `School ID`is no longer a regular column. It is now shown at the left in the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df = schools_df.set_index('School ID')\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HeardLibrary/digital-scholarship/raw/master/data/gis/wg/Metro_Nashville_Schools.csv'\n",
    "schools_df = pd.read_csv(url)\n",
    "schools_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use values from a column as the row index but want that column to remain as part of the data, you can create the index from the column rather than converting the column into the index. The following cell does that. Notice that `School ID` appears both on the left side (as the row label index) but also as the third data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df.index = schools_df['School ID']\n",
    "schools_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for reading and writing from files\n",
    "\n",
    "`pd.read_csv()` read from a CSV file into a data frame.\n",
    "\n",
    "`pd.to_csv()` write from a data frame to a CSV file.\n",
    "\n",
    "`pd.read_excel()` read from an Excel file into a data frame.\n",
    "\n",
    "`pd.to_excel()` write from a data frame to an Excel file.\n",
    "\n",
    "For details about reading from particular sheets in an Excel file, delimiters other than commas, etc. see the [pandas User Guide](https://pandas.pydata.org/docs/user_guide/io.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis 0 = rows, axis 1 = columns\n",
    "dff.mean(axis=1)\n",
    "\n",
    "df.sort_index(axis=1, ascending=False) # sorting across rows\n",
    "\n",
    "Pandas Operator \tBoolean \tRequires\n",
    "& \tand \tAll required to True\n",
    "| \tor \tIf any are True\n",
    "~ \tnot \tThe opposite\n",
    "\n",
    "See https://constellate.org/tutorials/pandas-2\n",
    "for filtering, dropping rows, changing values by condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "file_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
