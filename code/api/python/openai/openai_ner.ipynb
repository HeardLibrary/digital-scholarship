{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo script for doing Named Entity Recognition (NER) using ChatGPT\n",
    "\n",
    "To run this script, you need to first create an account on the OpenAI developer platform by going to <https://platform.openai.com/> and clicking on the `Sign up` button. As of 2024-02-07, the pricing is as follows: Charges per token (1000 tokens is roughly 750 words); `$0.0005` per 1000 tokens for gpt3.5-turbo, new accounts start with a $5 credit (check your usage under profile page). This credit expires after a certain number of months, so don't sign up until you are actually ready to experiment. Once the credit runs out, you will need to add to your credit balance using a credit card. \n",
    "\n",
    "After creating your account, go to the [API keys](https://platform.openai.com/api-keys) option and click `Create new secret key`. If you are working on your own computer, you can allow \"All\" permissions. You will have one opportunity to copy the secret key once it is generated, so be prepared to either save it in a text file or add it to the code below. Note the warning about hard-coding the key within this script!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line only needs to be run one time on your system to install the OpenAI Python module.\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook reads your API key and creates a client object that will be used in the rest of the script. You only need to run this cell once each time you load the notebook unless you change the base prompt.\n",
    "\n",
    "Resources:\n",
    "- <https://kili-technology.com/data-labeling/machine-learning/using-chatgpt-to-pre-annotate-named-entities-recognition-labeling-tasks>\n",
    "- <https://github.com/openai/openai-python>\n",
    "- <https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_ner.ipynb, a Python script for using the ChatGPT API to do entity recognition.\n",
    "\n",
    "# (c) 2024 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Authors: Emily Yan and Steve Baskauf\n",
    "\n",
    "script_version = '0.0.1'\n",
    "version_modified = '2024-02-07'\n",
    "\n",
    "# -------------------\n",
    "# Imports\n",
    "# -------------------\n",
    "\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# -------------------\n",
    "# Global variables\n",
    "# -------------------\n",
    "\n",
    "# create a base prompt that will be used for all questions\n",
    "BASE_PROMPT = \"\"\"From the text below, give me the list of:\n",
    "- object named entity\n",
    "- location named entity\n",
    "- person named entity\n",
    "- miscellaneous named entity.\n",
    "Format the output in json with the following keys:\n",
    "- OBJECT for organization named entity\n",
    "- LOCATION for location named entity\n",
    "- PERSON for person named entity\n",
    "- MISCELLANEOUS for miscellaneous named entity.\n",
    "Text below:\n",
    "\"\"\"\n",
    "\n",
    "# set model parameters\n",
    "OPENAI_QUERY_PARAMS = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # gpt-3.5-turbo best suited for understanding + generating natural language\n",
    "    \"temperature\": 0, # temperature affects the amount of \"creativity\" that the model will use to generate the response; 0 means no randomness\n",
    "    \"max_tokens\": 1024 # Limit the number of tokens that can be used. A token is roughly equivalent to a word.\n",
    "}\n",
    "\n",
    "# If you are ONLY going to use this notebook locally, you can hard code your API key here. However, that is really a bad practice if\n",
    "# there is any chance that you will share this notebook or push it to a public repository. It is better to keep the key in a file that\n",
    "# is in a separate location that is unrelated to where you are keeping the code. The code that follows the next line will read the key\n",
    "# from a plain text file in your home directory.\n",
    "#client = OpenAI(api_key='')\n",
    "\n",
    "# If saving the API key in a file in your home directory, change the following string value to the filename that you used.\n",
    "openai_key_filename = 'open_ai_api_key_text_analysis.txt'\n",
    "\n",
    "# Read the API key from a file in the home directory. The file should contain only the key and no other text.\n",
    "home = str(Path.home()) # gets path to home directory; supposed to work for both Win and Mac\n",
    "with open(home + '/' + openai_key_filename, 'r') as file:\n",
    "    api_key_string = file.read().strip() # remove any leading or trailing white space or newlines\n",
    "\n",
    "CLIENT = OpenAI(api_key=api_key_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about the request function:\n",
    "\n",
    "- Has parameters prompt (the specific text you want to perform NER on), default base_prompt (can be overridden with a different base prompt during function call), and openai_query_params\n",
    "- model: gpt-3.5-turbo best suited for understanding + generating natural language\n",
    "- temperature: sampling temperature between 0 and 2; higher temperature = more random/abstracted output, lower temperature = more focused output\n",
    "- max_tokens: cap on number of tokens that can be generated in the chat completion\n",
    "- messages: establish preliminary dialogue and help prevent some user from significantly misguiding the model with a malicious input prompt; “system” message helps prime model for specific task (NER), “user” message is from user to model, “assistant” message would be from model to user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# Function definitions\n",
    "# -------------------\n",
    "\n",
    "def ask_openai(prompt: str, base_prompt=BASE_PROMPT, openai_query_params=OPENAI_QUERY_PARAMS) -> str:\n",
    "    \"\"\"Send a request to OpenAI's ChatGPT API to do entity recognition. The prompt should be a sentence or paragraph of text\n",
    "    on which you want to perform NER.\n",
    "    \n",
    "    The function returns a JSON-formatted string with the named entities extracted from the input text.\n",
    "    \"\"\"\n",
    "    response = CLIENT.chat.completions.create(\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a smart and intelligent Named Entity Recognition (NER) system. I will provide you the definition of the entities you need to extract, the sentence from where you extract the entities and the output format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": base_prompt + prompt\n",
    "        }        \n",
    "    ],\n",
    "        **openai_query_params\n",
    "    )\n",
    "    \n",
    "    return(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example requests an analysis and directly prints the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "example_text = 'Vanderbilt University is a private research university in Nashville, Tennessee. It was founded in 1873.'\n",
    "print(ask_openai(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To experiment, replace the input text with your own text and run this cell. The response will be stored in the `data` variable as a dictionary of lists, which can be used for further analysis in subsequent cells without re-running the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom input\n",
    "input_text = '''The House committee investigating the Jan. 6 attack on the U.S. Capitol on Tuesday evening unanimously approved a criminal contempt report against Steve Bannon, an ally of former President Donald Trump's, for defying a subpoena from the panel.'''\n",
    "#input_text = '''Pax, depicting the Crucifixion with the Virgin raising her hands, Saint John the Evangelist, and two angels'''\n",
    "data_text = ask_openai(input_text)\n",
    "\n",
    "# Interpret the response data as a JSON string and convert it to a Python data structure.\n",
    "data = json.loads(data_text)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('People mentioned in the text:')\n",
    "for person in data['PERSON']:\n",
    "    print(person)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
