---
permalink: /script/codegraf/026/
title: CodeGraf - R Intro to stats - Factors and the t-test of means
breadcrumb: O26
---

Previous lesson: [basic statistics and plots](../026)

# R Intro to stats: Factors and the t-test of means

This is the first lesson in the module Introduction to statistics with R. This module assumes that you have some basic familiarity with statistics, although some background is reviewed with each topic. It also assumes that you have [installed R and RStudio](../003) and completed the [R for beginners module](../011) or have equivalent experience gained on your own.

In this lesson, we will gain a more in-depth understanding of *factors* in R and will learn the details necessary to conduct a valid t-test of means.

**Learning objectives** At the end of this lesson, the learner will be able to:
- descr

Total video time:  m  s

# Links

[Lesson R script at GitHub](https://github.com/HeardLibrary/digital-scholarship/blob/master/code/codegraf/026/026.R)

[Lesson slides](../slides/lesson026.pdf)

----

## Introduction to the module (1m22s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/7OBPYrBcZBY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

----

# Factors and the t-test of means

## Factors (5m10s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/q4jOF5sTFtI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

A **factor** is a data structure used for grouping data. The categories of a factor are called **levels**. 

The `factor()` function can be used to convert a vector into a factor:

```
factor_object <- factor(vector)
```

Factors are viewed by their string labels, but are actually stored as numbers.

----

## Data frames and factors (4m11s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/vnds12eeUlc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

When data frames are constructed using the `data.frame()` function, character vectors are automatically converted into factors. 

When data frames read in using the `read.csv()` function, character vectors are also automatically converted to factors. (This does not happen with tibble data frames.)

To convert a factor to a vector, use the `as.character()` function.

----

## t-test of means (4m31s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/BdaM0ZkC7Vs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The command to carry out a t-test of means with equal variances is:

```
t.test(dep_vec ~ ind_vec, var.equal=TRUE)
```

when the data input is by vectors, or

```
t.test(dep_col ~ ind_col, data=data_frame, var.equal=TRUE)
```

when the data are input from data frame columns. 

----

## Review of p-value (P) (8m54s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/DZJlkT2F8YY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

P is the probability that we would get results like these samples if there were really no difference between the means of the two groups (the variation we see is cause by random unrepresentative sampling).

If the value of P is less than 0.05, it is unlikely that the means of the two groups are actually the same, and we assume that the *null hypothesis* (that the groups are the same) is wrong. We conclude that the two groups are significantly different.

If P > 0.05, it may be that the two groups are not different, but it could also mean that the groups are different but our experiment was too bad to detect it.

Statistical *power* is the ability of a test to detect differences that are real. We can increase the power of a test by reducing variability in the experimental conditions, or by increasing the sample size.

When statistical power is very great, small effects can become statistically significant even if they are not actually very important.

----

## Testing for normality (7m06s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/Hk-UV2iLmyQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

There are three main assumptions that must be met in order for a t-test of means to be valid:
1. Independence of the two samples.
2. Each group normally distributed.
3. Variances of the two groups are the same.

To test the assumption that each group is normally distributed, we can visualize the distribution with a histogram or normal quantile (Q-Q) plot, and we can run the Shapiro-Wilkes test to do a numerical assessment.

To create a histogram, use:

```
hist(data_frame$column)
```

where the column has been filtered to contain only one of the levels of the factor. To create a normal quantile plot, use:

```
qqnorm(data_frame$column, datax = TRUE)
```

The Shapiro-Wilks test is:

```
shapiro.test(data_frame$column)
```

If the result has P < 0.05, the data deviate significantly from normal.

The t-test of means is relatively robust to deviations from normality. So the test can be valid even when the data are not as normal as we would like.

----

## Testing the assumption of equal variances (2m02s)

<iframe width="1120" height="630" src="https://www.youtube.com/embed/bxD0eYLavJ8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Bartlett's test can be used to test the assumption of equal variances between the two groups:

```
bartlett.test(dep_col ~ ind_col, data=data_frame)
```

If the result has P < 0.05, the variances are significantly different. Bartlett's test requires that the data be normally distributed, but if they aren't the t-test is invalid anyway.

----

# Practice assignment

1. Re



Next lesson: [x](../027)

----
Revised 2020-10-12
